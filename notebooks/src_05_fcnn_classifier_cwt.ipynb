{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55418780-d77e-478a-b365-f5795e54b630",
   "metadata": {},
   "source": [
    "# FCNN CWT Classifier for Plant Waves\n",
    "----\n",
    "\n",
    "#### PREPROCESSING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47863947-8b53-4c6f-b7f7-12b3636d3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "%run ../src/utils/constants.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a9b2a-3313-4d0c-992f-da50d85acf8a",
   "metadata": {},
   "source": [
    "Load raw data that has been split into train, test, and validation sets for the 81k and 191k cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53efc89-4e97-4b8d-816e-1e372b76b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pickle_train81k = DATASETS_DIR / \"train-81k-stratified-without-neutral.pkl\"\n",
    "path_to_pickle_train191k = DATASETS_DIR / \"train-191k-stratified-without-neutral.pkl\"\n",
    "path_to_pickle_test81k = DATASETS_DIR / \"test-81k-stratified-without-neutral.pkl\"\n",
    "path_to_pickle_val81k = DATASETS_DIR / \"val-81k-stratified-without-neutral.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70130b7b-9884-431a-940c-41277af5e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_pickle_train81k, 'rb') as train_81k_file:\n",
    "    train_81k = pickle.load(train_81k_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24736e8f-afa4-4e0e-a65b-6e4d36a9e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_pickle_train191k, 'rb') as train_191k_file:\n",
    "    train_191k = pickle.load(train_191k_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936f8d8-0e4a-4f06-a15c-7f893f7c353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_pickle_test81k, 'rb') as test_81k_file:\n",
    "    test_81k = pickle.load(test_81k_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b47f0a-b530-42cb-9cf8-8c2d6bc3becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_pickle_val81k, 'rb') as val_81k_file:\n",
    "    val_81k = pickle.load(val_81k_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610d4c1-ca29-4230-a967-437335d4778b",
   "metadata": {},
   "source": [
    "Define method for cwt feature extraction for train, test, validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c619b01-eae4-411f-a1d3-40bf6b6694d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cwt_features(wav_slice):\n",
    "    wav_slice_np = wav_slice.numpy()\n",
    "    downsample_factor = 50\n",
    "    downsampled_wav = wav_slice_np[::downsample_factor]\n",
    "\n",
    "    # Values were determined experimentally.\n",
    "    freq_range = (1, 6)\n",
    "    scales = SAMPLING_RATE / (downsample_factor * 2 * np.arange(freq_range[0], freq_range[1]))\n",
    "\n",
    "    cwt_coeffs, frequencies = pywt.cwt(downsampled_wav, scales, wavelet='morl')\n",
    "\n",
    "    # Compute abs because it will be used for plot as well and values are more obvious.\n",
    "    abs_coeffs = np.abs(cwt_coeffs)\n",
    "\n",
    "    # Normalization (per-sample)\n",
    "    mean_coeffs = np.mean(abs_coeffs)\n",
    "    std_dev_coeffs = np.std(abs_coeffs)\n",
    "\n",
    "    normalized_coeffs = (abs_coeffs - mean_coeffs) / (std_dev_coeffs + 0.00000001)\n",
    "    \n",
    "    return normalized_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9711e7-5c87-4de8-ac71-c1d3dd0122fb",
   "metadata": {},
   "source": [
    "While ignoring the class `Neutral`, separate wave slices and labels, and create a Tensor dataset for train, test, val."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd2e0f-6007-4010-8127-14a7917a3813",
   "metadata": {},
   "source": [
    "##### Train 81k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f338a9a5-e260-46a8-8247-6be3b12c513e",
   "metadata": {},
   "source": [
    "Extract spectral features, i.e. the CWT coefficients. Downsample the signal for faster computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1630bcb-bdcf-4bb1-a530-65793d60e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_slices_train_81k = []\n",
    "labels_train_81k = []\n",
    "counter = 0\n",
    "for segment_train_81k in tqdm(train_81k):  \n",
    "    cwt_coeffs_train_81k = extract_cwt_features(segment_train_81k[0])\n",
    "    sample_features_train_81k = cwt_coeffs_train_81k.flatten()\n",
    "    wav_slices_train_81k.append(sample_features_train_81k)\n",
    "    \n",
    "    labels_train_81k.append(segment_train_81k[1])\n",
    "\n",
    "    if counter == 0: \n",
    "        print(\"cwt_coeffs_train_81k.shape\", cwt_coeffs_train_81k.shape)\n",
    "        print(\"sample_features_train_81k.shape\", sample_features_train_81k.shape)\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f918bb8-dbf6-43bb-a4db-bede8bb0d034",
   "metadata": {},
   "source": [
    "Create train dataset 81k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea6b56-e125-44c6-af1d-a9a79c33db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_slices_train_81k = torch.tensor(np.array(wav_slices_train_81k), dtype=torch.float32)\n",
    "labels_train_81k = torch.tensor(np.array(labels_train_81k), dtype=torch.long)\n",
    "dataset_train_81k = TensorDataset(wav_slices_train_81k, labels_train_81k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd74e19-8547-43e4-80bf-84939afc3c80",
   "metadata": {},
   "source": [
    "##### Test 81k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7476b7-99ec-47dc-b75b-5b8e3e2e8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_slices_test_81k = []\n",
    "labels_test_81k = []\n",
    "for segment_test_81k in tqdm(test_81k):  \n",
    "    cwt_coeffs_test_81k = extract_cwt_features(segment_test_81k[0])\n",
    "    sample_features_test_81k = cwt_coeffs_test_81k.flatten()\n",
    "    wav_slices_test_81k.append(sample_features_test_81k)\n",
    "    \n",
    "    labels_test_81k.append(segment_test_81k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef85e334-5529-4dc2-82a6-8d668c1c5d8d",
   "metadata": {},
   "source": [
    "Create test dataset 81k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b0a58-e7bb-4bef-a83c-bdf4c07f9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_slices_test_81k = torch.tensor(np.array(wav_slices_test_81k), dtype=torch.float32)\n",
    "labels_test_81k = torch.tensor(np.array(labels_test_81k), dtype=torch.long)\n",
    "dataset_test_81k = TensorDataset(wav_slices_test_81k, labels_test_81k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22cb01e-c2b8-4bdc-95a6-9f4f6737dfbf",
   "metadata": {},
   "source": [
    "##### Validation 81k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca67e6-2976-4503-8637-6d3b3b99939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_slices_val_81k = []\n",
    "labels_val_81k = []\n",
    "for segment_val_81k in tqdm(val_81k):  \n",
    "    cwt_coeffs_val_81k = extract_cwt_features(segment_val_81k[0])\n",
    "    sample_features_val_81k = cwt_coeffs_val_81k.flatten()\n",
    "    wav_slices_val_81k.append(sample_features_val_81k)\n",
    "    \n",
    "    labels_val_81k.append(segment_val_81k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e957254-8f7b-483b-a8a3-ebb03a36d290",
   "metadata": {},
   "source": [
    "Create validation dataset 81k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d4a285-747c-44c9-a85b-30a6d4233c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_slices_val_81k = torch.tensor(np.array(wav_slices_val_81k), dtype=torch.float32)\n",
    "labels_val_81k = torch.tensor(np.array(labels_val_81k), dtype=torch.long)\n",
    "dataset_val_81k = TensorDataset(wav_slices_val_81k, labels_val_81k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb008a-7abe-4bde-ad32-d8d25dc73fac",
   "metadata": {},
   "source": [
    "#### Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce5a12-01f8-40ae-b74b-9e8871fd144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63aefae-6310-4a3f-a89a-275513ef043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train81k_loader = DataLoader(dataset_train_81k, batch_size)\n",
    "test81k_loader = DataLoader(dataset_test_81k, batch_size)\n",
    "val81k_loader = DataLoader(dataset_val_81k, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c235b1-590b-4888-9d99-76be48aef9cf",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c7c87-349a-4a0c-81d8-cf6644209bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import math\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a249a2bc-e6ed-4e35-a8b5-03fb885cb7ee",
   "metadata": {},
   "source": [
    "Define the FCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0d001-9473-4404-accb-11cad0776bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    layers = []\n",
    "\n",
    "    INPUT_DIM = 1000\n",
    "    N_CLASSES = 6\n",
    "    dropout_rate = trial.suggest_categorical(\"dropout_rate\", [0.0, 0.1, 0.2])\n",
    "\n",
    "    hidden_dim_1 = trial.suggest_categorical(\"hidden_dim_1\", [2 ** i for i in range(4, 8)])\n",
    "\n",
    "    layers.append(torch.nn.Linear(INPUT_DIM, hidden_dim_1))\n",
    "    layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Dropout(dropout_rate))\n",
    "\n",
    "    hidden_dim_2 = trial.suggest_categorical(\"hidden_dim_2\", [2 ** i for i in range(4, 7)])\n",
    "    \n",
    "    layers.append(torch.nn.Linear(hidden_dim_1, hidden_dim_2))\n",
    "    layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Dropout(dropout_rate))\n",
    "    \n",
    "    layers.append(torch.nn.Linear(hidden_dim_2, N_CLASSES))\n",
    "\n",
    "    config_dict = {\n",
    "        \"hidden_dim_1\": hidden_dim_1,\n",
    "        \"hidden_dim_2\": hidden_dim_2,\n",
    "        \"dropout_rate\": dropout_rate\n",
    "    }\n",
    "\n",
    "    return torch.nn.Sequential(*layers), config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b00e8c-7614-4453-b3e1-7676d3f22198",
   "metadata": {},
   "source": [
    "Define the objective function for optuna for the hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53784052-1111-4208-b29f-cbd92061709a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Run without W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e4fa6-334f-40c0-915d-3a2c301c1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_without_wandb(trial): \n",
    "    model, config_dict = define_model(trial)\n",
    "\n",
    "    lr = trial.suggest_categorical('lr', [0.0001, 0.001, 0.01])\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    print(config_dict)\n",
    "    name_experiment = (f\"{trial.number}_{NAME_CORE}_lr-{lr}_hidden1-{config_dict['hidden_dim_1']}_hidden2-\"\n",
    "                       f\"{config_dict['hidden_dim_2']}_dr-{config_dict['dropout_rate']}\")\n",
    "\n",
    "    config_dict[\"lr\"] = lr\n",
    "    config_dict[\"epochs\"] = NUM_EPOCHS\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        for batch_data, batch_labels in tqdm(train81k_loader):          \n",
    "            # zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward pass\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_labels in tqdm(val81k_loader): \n",
    "                output = model(batch_data)\n",
    "\n",
    "                predicted = output.argmax(dim=1)\n",
    "                all_preds.extend(predicted.numpy())\n",
    "                all_labels.extend(batch_labels.numpy())\n",
    "\n",
    "        # TODO: explicitely state in written thesis that zero_division=0.0\n",
    "        balanced_accuracy = balanced_accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        trial.report(balanced_accuracy, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return balanced_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b56d1-2cf4-4fb3-9a06-cd2867d74c37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Run with W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bb77c-a7ae-4808-b432-5fcc0caa33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial): \n",
    "    model, config_dict = define_model(trial)\n",
    "\n",
    "    lr = trial.suggest_categorical('lr', [0.0001, 0.001, 0.01])\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    print(config_dict)\n",
    "    name_experiment = (f\"{trial.number}_{NAME_CORE}_lr-{lr}_hidden1-{config_dict['hidden_dim_1']}_hidden2-\"\n",
    "                       f\"{config_dict['hidden_dim_2']}_dr-{config_dict['dropout_rate']}\")\n",
    "\n",
    "    config_dict[\"lr\"] = lr\n",
    "    config_dict[\"epochs\"] = NUM_EPOCHS\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"model_\" + NAME_CORE + \"-hpo\",\n",
    "        dir=LOGS_DIR,\n",
    "        name=name_experiment,\n",
    "        config=config_dict\n",
    "    )\n",
    "\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        for batch_data, batch_labels in tqdm(train81k_loader):          \n",
    "            # zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward pass\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_labels in tqdm(val81k_loader): \n",
    "                output = model(batch_data)\n",
    "\n",
    "                predicted = output.argmax(dim=1)\n",
    "                all_preds.extend(predicted.numpy())\n",
    "                all_labels.extend(batch_labels.numpy())\n",
    "\n",
    "        # TODO: explicitely state in written thesis that zero_division=0.0\n",
    "        balanced_accuracy = balanced_accuracy_score(all_labels, all_preds)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1_class = f1_score(all_labels, all_preds, average=None, zero_division=0.0)\n",
    "        f1_weighted = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0.0)\n",
    "        recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0.0)\n",
    "        precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0.0)\n",
    "\n",
    "        trial.report(balanced_accuracy, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        metrics = {\n",
    "            \"balanced_accuracy\": balanced_accuracy,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1_weighted\": f1_weighted,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision\n",
    "        }\n",
    "\n",
    "        wandb_input = metrics\n",
    "        wandb.log(wandb_input)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return balanced_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89f988-a9ea-423a-8d6f-1d5c7615d3b3",
   "metadata": {},
   "source": [
    "##### Run hyperparameter optimization using optuna. Specify a study name and define the search space for the grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2cd8f6-9f16-4c13-95ef-3f5d400511c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_CORE = \"fcnn_cwt_6_81k_search_108\"\n",
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074591d0-6457-49af-af4a-1ffb94edb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'lr': [0.0001, 0.001, 0.01],\n",
    "    'hidden_dim_1': [2 ** i for i in range(4, 8)],\n",
    "    'hidden_dim_2': [2 ** i for i in range(4, 7)],\n",
    "    \"dropout_rate\": [0, 0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a1c54-8983-4a95-b950-444596322cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_combi = 1\n",
    "for i in search_space:\n",
    "    num_combi *= len(search_space[i])\n",
    "num_combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76683d87-065b-4b39-981f-8b13ee75c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study = optuna.create_study(sampler=sampler, study_name=NAME_CORE, storage=\"sqlite:///hpo_\" + NAME_CORE + \".db\",\n",
    "                            direction=\"maximize\", load_if_exists=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff5d6c-ed39-4759-9bbf-fbd04e21c6b0",
   "metadata": {},
   "source": [
    "ADJUST `objective` function: with or without W&B!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66bbe9-30c1-410d-88d0-169fc1ff32ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study.optimize(objective_without_wandb, n_trials=num_combi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a21577-9e3d-4ae8-850e-89b616554358",
   "metadata": {},
   "source": [
    "Closer look into the trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf469d-5105-4b9f-b8e7-12505e11ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580d071-60b1-468b-935c-c9ddc0de1440",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial_ = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial_.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial_.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca7d44-9c34-4eab-b619-8c09ab92efbc",
   "metadata": {},
   "source": [
    "#### Training the Baseline FCNN.\n",
    "10 times training with the best HP from HPO, and then average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c62f20-a78f-43db-958b-e6f8b937c6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b20234-c6f3-4af9-b03b-73c8cff9eb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748b45a-9596-4ab0-85fa-b15191cd0a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb43cba-b17b-4a68-864e-6efcfb9824a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58798de-dcde-4035-8a80-34a416ec515b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe808f1e-acf1-41a1-a752-b4b8fa0da9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55a52f-7490-4cfa-8103-d760638b25fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ca74ec5-c61d-478c-a22e-c1eaced9f60d",
   "metadata": {},
   "source": [
    "#### Testing the Baseline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becc3ca-9df7-4d41-a8f0-9c732799bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%run ../src/utils/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6cedcf-458e-47e9-8d80-d54017a9ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_81k_folder = \"test-81k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d38062-26e8-4aa0-8929-064329279f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2a9dd-2aab-4ba9-b3be-99f54ca808c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
